{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredatorPreyENV(gym.Env):\n",
    "    # The primary purpose of PredatorPreyENV is to store configuration settings and sensitive information\n",
    "    #  Python class named PredatorPreyENV that inherits from the custom gym.Env\n",
    "    def __init__(self, screen_width=800, screen_height=600):\n",
    "        super(PredatorPreyENV, self).__init__()\n",
    "\n",
    "        # Define the screen dimensions\n",
    "        self.screen_width = screen_width\n",
    "        self.screen_height = screen_height\n",
    "\n",
    "        # defining the agent policies\n",
    "        self.blue_dot_radius = 40\n",
    "        self.direction_line_length = 40\n",
    "        self.blue_dot_health = 50\n",
    "        self.red_dot_health = 50\n",
    "\n",
    "        # Define 4 discreet action space (left, right, up, down)\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "\n",
    "        # Define observation space (positions of blue dot and red dot)\n",
    "        self.observation_space = spaces.Box(low=np.array([0, 0, 0, 0], dtype=np.float32), high=np.array(\n",
    "            [self.screen_width / 2, self.screen_height, self.screen_width, self.screen_height], dtype=np.float32),\n",
    "                                            dtype=np.float32)\n",
    "\n",
    "        # Initialize the pygame window\n",
    "        pygame.init()\n",
    "        self.screen = pygame.display.set_mode((self.screen_width, self.screen_height))\n",
    "        pygame.display.set_caption('Dots Moving Environment')\n",
    "\n",
    "        # Initialize the positions of the blue and red dots\n",
    "        # self.blue_dot_pos = np.array([self.screen_width / 4, self.screen_height / 2], dtype=np.float32)\n",
    "        self.blue_dot_pos = np.array([self.screen_width / 4, self.screen_height / 2], dtype=np.float32)\n",
    "\n",
    "        # self.red_dot_pos = np.array([3 * self.screen_width / 4, self.screen_height / 2], dtype=np.float32)\n",
    "        self.red_dot_pos = np.array([3 * self.screen_width / 4, self.screen_height / 2], dtype=np.float32)\n",
    "\n",
    "        # Define grid line properties\n",
    "        self.grid_color = (210, 210, 210)\n",
    "        self.grid_spacing = 40  # Adjust this value to change the grid spacing\n",
    "\n",
    "        pygame.font.init()\n",
    "        self.font = pygame.font.Font(None, 36)\n",
    "\n",
    "        self.total_reward = 0\n",
    "    #     keep track of the cumulative reward earned by the agent as it interacts with the environment\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the positions of the blue and red dots at start of each episodes\n",
    "        # self.blue_dot_pos = np.array([0, 0], dtype=np.float32)\n",
    "        self.blue_dot_pos = np.array([self.screen_width / 4, self.screen_height / 2], dtype=np.float32)\n",
    "\n",
    "        # self.red_dot_pos = np.array([3 * self.screen_width / 4, self.screen_height / 2], dtype=np.float32)\n",
    "\n",
    "        # Reset the position of the red dot to the middle of the screen\n",
    "        # self.red_dot_pos = np.array([self.screen_width / 2, self.screen_height / 2], dtype=np.float32)\n",
    "        self.red_dot_pos = np.array([3 * self.screen_width / 4, self.screen_height / 2], dtype=np.float32)\n",
    "\n",
    "        self.blue_dot_health = 50\n",
    "        self.total_reward = 0\n",
    "        return np.concatenate([self.blue_dot_pos, self.red_dot_pos])\n",
    "\n",
    "    # This function essentially describes how the blue and red dots interact\n",
    "    # based on the selected actions, handle collisions, and update their positions and rewards within the environment.\n",
    "    def step(self, action):  #per second 1 frame pass what happens determines step function\n",
    "        # truncated == false\n",
    "        # Define the movement speed\n",
    "        # self used to access variables\n",
    "        move_speed = 0.8   #blue\n",
    "\n",
    "        # Separate the action for blue and red dots\n",
    "        action_blue_dot, action_red_dot = action\n",
    "        # POLICIES\n",
    "        if action_blue_dot == 0:  # Move blue dot left\n",
    "            self.blue_dot_pos[0] -= move_speed\n",
    "        elif action_blue_dot == 1:  # Move blue dot right\n",
    "            self.blue_dot_pos[0] += move_speed\n",
    "        elif action_blue_dot == 2:  # Move blue dot up\n",
    "            self.blue_dot_pos[1] -= move_speed\n",
    "        elif action_blue_dot == 3:  # Move blue dot down\n",
    "            self.blue_dot_pos[1] += move_speed\n",
    "\n",
    "        move_speed = 0.1   # red\n",
    "\n",
    "        # Calculate the direction vector from the red dot to the blue dot by subtracting\n",
    "        direction = self.blue_dot_pos - self.red_dot_pos\n",
    "\n",
    "        # Normalize the direction vector by dividing the vector by its magnitude (length) to turn it into a unit vector\n",
    "        direction /= np.linalg.norm(direction)\n",
    "        # normalized vector (direction) indicates the direction from the red dot to the blue dot.\n",
    "        #print(\"Direction: \", direction)\n",
    "        distance_between_centers = np.linalg.norm(self.blue_dot_pos - self.red_dot_pos)\n",
    "        # calculates the Euclidean distance between the centers of the blue and red dots,\n",
    "        # measures how far apart the two dots are in terms of pixel distance.\n",
    "\n",
    "        # radii for collision detection. The red_dot_radius is set to be 15 pixels smaller than the blue_dot_radius.\n",
    "        blue_dot_radius = self.blue_dot_radius\n",
    "        red_dot_radius = blue_dot_radius - 15\n",
    "        reward = 0\n",
    "        done = False\n",
    "\n",
    "        # Check if the dots collide with each other\n",
    "        # checking if the distance between the centers of the blue and red dots (distance_between_centers)\n",
    "        # is less than the sum of their radii (blue_dot_radius + red_dot_radius)\n",
    "        if distance_between_centers < blue_dot_radius + red_dot_radius:\n",
    "            # Separate the dots by moving the red dot away from the blue dot\n",
    "            self.red_dot_pos -= -50.0 + move_speed * direction\n",
    "            self.blue_dot_health -= self.red_dot_attack_dmg\n",
    "            if(self.blue_dot_health <= 0):\n",
    "                done = True\n",
    "            reward -= 5\n",
    "            #print(\"collision\")\n",
    "\n",
    "        else:\n",
    "            # Move the red dot towards the blue dot with a fixed speed\n",
    "            self.red_dot_pos += move_speed * direction\n",
    "\n",
    "        # Clip blue dot position to stay within the first half of the screen\n",
    "        self.blue_dot_pos[0] = np.clip(self.blue_dot_pos[0], 0, self.screen_width)\n",
    "        self.blue_dot_pos[1] = np.clip(self.blue_dot_pos[1], 0, self.screen_height)\n",
    "\n",
    "        # Clip red dot position to stay within the entire screen\n",
    "        self.red_dot_pos = np.clip(self.red_dot_pos, [0, 0], [self.screen_width, self.screen_height])\n",
    "\n",
    "        # Define a simple reward function (e.g., distance between the two dots)\n",
    "        # reward = -np.linalg.norm(self.blue_dot_pos - self.red_dot_pos)\n",
    "        self.total_reward += reward\n",
    "\n",
    "        # Check if the dots are close to each other (you can adjust the distance threshold as needed)\n",
    "        # done = np.linalg.norm(self.blue_dot_pos - self.red_dot_pos) < 10\n",
    "        return np.concatenate([self.blue_dot_pos, self.red_dot_pos]), reward, done, {}\n",
    "    # done flag indicating the end of the episode, and an empty dictionary ({}) for additional information\n",
    "\n",
    "    def display_total_reward(self):\n",
    "        text_surface = self.font.render(f\"Reward: {self.total_reward: .2f} Blue Health: {self.blue_dot_health}\", True, (0, 0, 0))\n",
    "        # the reward and blue dot health values text\n",
    "        text_rect = text_surface.get_rect()\n",
    "        # position the text on the pygame window.\n",
    "        text_rect.center = (self.screen_width - 200, 10)\n",
    "        self.screen.blit(text_surface, text_rect)\n",
    "    # The blit method is used to draw the text surface (text_surface) onto the pygame window (self.screen)\n",
    "\n",
    "    # render function is responsible for creating a visual representation of the environment\n",
    "    def render(self, action_blue, action_red):\n",
    "        # Clear the screen\n",
    "        self.screen.fill((229, 222, 248))\n",
    "\n",
    "        # Draw grid lines\n",
    "        for x in range(0, self.screen_width, self.grid_spacing):\n",
    "            pygame.draw.line(self.screen, self.grid_color, (x, 0), (x, self.screen_height), 1)\n",
    "        for y in range(0, self.screen_height, self.grid_spacing):\n",
    "            pygame.draw.line(self.screen, self.grid_color, (0, y), (self.screen_width, y), 1)\n",
    "\n",
    "        # Draw blue dot\n",
    "        pygame.draw.circle(self.screen, (141,144,226), (int(self.blue_dot_pos[0]), int(self.blue_dot_pos[1])), self.blue_dot_radius)\n",
    "\n",
    "        # Draw red dot\n",
    "        pygame.draw.circle(self.screen, (158, 50, 90), (int(self.red_dot_pos[0]), int(self.red_dot_pos[1])), self.blue_dot_radius - 10)\n",
    "\n",
    "        # calculating the position of facing direction lines\n",
    "        blue_dot_direction_end = tuple(map(int, self.blue_dot_pos + self.direction_line_length * action_blue))\n",
    "        red_dot_direction_end = tuple(map(int, self.red_dot_pos + self.direction_line_length * action_red))\n",
    "\n",
    "        # direction line draw\n",
    "        pygame.draw.line(self.screen, (0, 0, 255), tuple(map(int, self.blue_dot_pos)), blue_dot_direction_end, 2)\n",
    "        pygame.draw.line(self.screen, (255, 0, 0), tuple(map(int, self.red_dot_pos)), red_dot_direction_end, 2)\n",
    "\n",
    "        self.display_total_reward()\n",
    "\n",
    "        # Update the display\n",
    "        pygame.display.update()\n",
    "\n",
    "    # def close(self):\n",
    "    #     pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PredatorPreyENV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('Training', 'Models', 'DQN_Model')\n",
    "log_path = os.path.join('Training', 'DQN_Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN('MlpPolicy', env=env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward} Std reward: {std_reward}\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
