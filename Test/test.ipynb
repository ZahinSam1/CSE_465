{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, agent_name, agent_index):\n",
    "        self.index = agent_index\n",
    "        self.agent = agent_name\n",
    "        self.health = None\n",
    "        self.isHit = False\n",
    "        self.move = True\n",
    "        self.movement_speed = 1.00\n",
    "        self.previous_position = np.array([0, 0], dtype=np.float32)\n",
    "        self.current_position = None\n",
    "        self.same_position = False\n",
    "        self.current_step = 0\n",
    "        self.action = None\n",
    "        pass\n",
    "\n",
    "    def agent_action(self, action):\n",
    "\n",
    "        pass\n",
    "\n",
    "    def agent_update(self, step, action, width, height):\n",
    "        if step > 0:\n",
    "            if (self.previous_position != self.current_position).all():\n",
    "                self.previous_position = self.current_position\n",
    "                self.same_position = False\n",
    "\n",
    "                if action:\n",
    "                    self.step_update(action)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                self.same_position = True\n",
    "\n",
    "    def agent_reset(self, width, height):\n",
    "        padding = 30\n",
    "        self.current_position = np.array(\n",
    "            [np.random.uniform(30, width - padding), np.random.uniform(30, width - padding)], dtype=np.float32)\n",
    "\n",
    "    def step_update(self, action, range_x, range_y):\n",
    "\n",
    "        if action == 0:\n",
    "            self.current_position[0] -= self.movement_speed\n",
    "        elif action == 1:\n",
    "            self.current_position[0] += self.movement_speed\n",
    "        elif action == 2:\n",
    "            self.current_position[1] -= self.movement_speed\n",
    "        elif action == 3:\n",
    "            self.current_position[1] += self.movement_speed\n",
    "        \n",
    "        self.current_position[0] = np.clip(self.current_position[0], 0, range_x)\n",
    "        self.current_position[1] = np.clip(self.current_position[1], 0, range_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gymnasium.spaces import Discrete, Box, MultiDiscrete\n",
    "from gymnasium import Env\n",
    "import numpy as np\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameEnv(Env):\n",
    "    def __init__(self, screen_width=400, screen_height=400, render_mode='human'):\n",
    "        super(GameEnv, self).__init__()\n",
    "\n",
    "        # defining the screen dimension for render purpose\n",
    "        self.screen_width = screen_width\n",
    "        self.screen_height = screen_height\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        # defining the observation and action spaces for all the agents\n",
    "        \n",
    "        self.observation_space = Box(low=np.array([0, 0, 0, 0], dtype=np.float32),\n",
    "                                    high=np.array([self.screen_width, self.screen_height, self.screen_width, self.screen_height], dtype=np.float32),\n",
    "                                    dtype=np.float32)\n",
    "\n",
    "        # the pygame window should be initialized in the render function\n",
    "\n",
    "        # setting the total number of agent\n",
    "        \n",
    "        self.number_of_prey = 1\n",
    "        self.number_of_predator = 1\n",
    "        self.prey_agent = None\n",
    "        self.predator_agent = None\n",
    "        self.number_of_agents = self.number_of_prey + self.number_of_prey\n",
    "\n",
    "        # defining the action space based on total number of predator and prey\n",
    "        self.action_space = Discrete(4)\n",
    "\n",
    "        # if self.number_of_prey > 0 and self.number_of_predator > 0:\n",
    "        #     self.agent_init()\n",
    "        # else:\n",
    "        #     self.prey_agents.append(Agent('prey', 0))\n",
    "        #     self.predator_agents.append(Agent('predator', 0))\n",
    "\n",
    "        # setting the total number of obstacles\n",
    "        self.total_obstacles = None\n",
    "\n",
    "        # keeping a counter to save the total steps\n",
    "        self.total_steps = 0\n",
    "\n",
    "        # initializing the pygame\n",
    "        pygame.init()\n",
    "\n",
    "        # setting the screen size\n",
    "        self.screen = pygame.display.set_mode((self.screen_width, self.screen_height))\n",
    "        pygame.display.set_caption('Multi Agent Environment(simple)')\n",
    "        \n",
    "        # keep the track of time of the rendering\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        # *it is set in milisec format (time is sec is time/1000)\n",
    "        self.total_running_time = 10000\n",
    "\n",
    "        # start the tick timer\n",
    "        self.start_time = None\n",
    "\n",
    "        # initializing the font\n",
    "        pygame.font.init()\n",
    "        self.font = pygame.font.Font(None, 36)\n",
    "\n",
    "    # this function rerturns the value of the action into 2 digits \n",
    "    # if the action_space.sample() gives 1 digit number\n",
    "    # * if  the number is 3 it will return 03 \n",
    "    # * if  the number is 14 then it will return 14\n",
    "    def expand_action_digit(self, action):\n",
    "\n",
    "        # this basically checks the number if it has 1 then fills the rest with 0\n",
    "        # if the number is 2 digits then it stays the same\n",
    "        action = str(action).zfill(2)\n",
    "        prey_action = int(action[0]) % 4\n",
    "        predator_action = int(action[1]) % 4\n",
    "        return prey_action, predator_action\n",
    "        \n",
    "\n",
    "    # this method will initialize the number of agents\n",
    "    # ! this must be called from outside\n",
    "    def agent_init(self):\n",
    "\n",
    "        prey_agents = Agent('prey', 0)\n",
    "\n",
    "        predator_agents = Agent('predator', 0)\n",
    "\n",
    "        self.prey_agent = prey_agents\n",
    "        self.predator_agent = predator_agents\n",
    "\n",
    "    # this function is used to explicitly set the number of agents\n",
    "    # ! this needs to be called from outside\n",
    "    def set_agent_number(self, prey_number, predator_number):\n",
    "        self.number_of_predator = predator_number\n",
    "        self.number_of_prey = prey_number\n",
    "\n",
    "    # the usual reset function\n",
    "    def reset(self, seed=0):\n",
    "        self.total_steps = 0\n",
    "        prey = self.prey_agent\n",
    "        predator = self.predator_agent\n",
    "        # for prey in self.prey_agents:\n",
    "        prey.agent_reset(width=self.screen_width, height=self.screen_height)\n",
    "        # observation.append([prey.index, prey.agent, prey.current_position])\n",
    "\n",
    "        # for predator in self.predator_agents:\n",
    "        predator.agent_reset(width=self.screen_width, height=self.screen_height)\n",
    "        # observation.append([predator.index, predator.agent, predator.current_position])\n",
    "        \n",
    "        self.prey_agent = prey\n",
    "        self.predator_agent = predator\n",
    "        observation = np.concatenate([self.prey_agent.current_position, self.predator_agent.current_position])\n",
    "        return observation, seed\n",
    "\n",
    "    # the step function\n",
    "    # this function is called for every timesteps\n",
    "    # this function updates the actions or states of agents in the env\n",
    "    # this function is called default by the algorithms of all sorts\n",
    "    # * it returns observation, reward, done, truncated, info\n",
    "    # * any game policy change can be done here\n",
    "    # * reward must be set here\n",
    "    def step(self, action):\n",
    "        # initializing the return variables\n",
    "        done = False\n",
    "        reward = 0.00\n",
    "        truncated = False\n",
    "        info = {}\n",
    "        current_time = 0\n",
    "        # when ever the step is starting set the start time\n",
    "        if self.total_steps == 0:\n",
    "            self.start_time = pygame.time.get_ticks()\n",
    "        else:\n",
    "            current_time = pygame.time.get_ticks()\n",
    "\n",
    "        elapsed_time = current_time + self.start_time\n",
    "        # handles the pygame window event when closing\n",
    "        # !if the window still crashes pygame.event needs to be managed properly\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                done = True\n",
    "                pygame.quit()\n",
    "        \n",
    "        # print(f'action: {action}')\n",
    "        # *the actions are split as required\n",
    "        # prey_action, predator_action = self.expand_action_digit(action)\n",
    "        predator_action = action\n",
    "        predator = self.predator_agent\n",
    "        # print(f'prey: {prey_action}, predator: {predator_action}')\n",
    "\n",
    "        # for prey in self.prey_agents:\n",
    "\n",
    "        #     # print(f'prey_{prey.index} = action:{action} current_position: {prey.current_position}')\n",
    "        #     prey.step_update(action=prey_action, range_x=self.screen_width - 10, range_y=self.screen_height - 10)\n",
    "        #     # print(f'prey_{prey.index}: new_position: {prey.current_position}')\n",
    "\n",
    "        #     observation.append({'index': prey.index, 'name': prey.agent, 'position': prey.current_position})\n",
    "                \n",
    "\n",
    "\n",
    "        # print(f'predator_{predator.index} = action:{action} current_position: {predator.current_position}')\n",
    "        predator.step_update(action=predator_action, range_x=self.screen_width - 10, range_y=self.screen_height - 10)\n",
    "        # print(f'predator_{predator.index}: new_position: {predator.current_position}')\n",
    "            \n",
    "        # !observation.append({'index': predator.index, 'name': predator.agent, 'position': predator.current_position})\n",
    "        # observation = self.predator_agent.current_position\n",
    "        observation = np.concatenate([self.prey_agent.current_position, self.predator_agent.current_position])\n",
    "\n",
    "        # print(f'observation: {self.predator_agent.current_position}')\n",
    "        self.total_steps += 1\n",
    "\n",
    "        direction = self.predator_agent.current_position - self.prey_agent.current_position\n",
    "\n",
    "        # Calculate the distance between the centers of the two dots\n",
    "        distance_between_centers = np.linalg.norm(direction)\n",
    "\n",
    "        # Check if there is a collision (distance <= sum of radii)\n",
    "        \n",
    "        \n",
    "        if elapsed_time < self.total_running_time:\n",
    "            if distance_between_centers <= 20:\n",
    "                reward += 20\n",
    "                done = True\n",
    "                # pygame.quit()\n",
    "                # self.close()\n",
    "\n",
    "        else:\n",
    "            done = True\n",
    "            reward -= 30\n",
    "            # pygame.quit()\n",
    "            # self.close()\n",
    "\n",
    "        # print(self.total_steps)\n",
    "        self.render()\n",
    "\n",
    "        return observation, reward, done, truncated, info\n",
    "        \n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == 'human':\n",
    "            screen = self.screen\n",
    "\n",
    "            # clear screen\n",
    "            screen.fill((255, 255, 255))\n",
    "            prey = self.prey_agent\n",
    "            pos_x, pos_y = prey.current_position\n",
    "            prey_radius = 10\n",
    "            pygame.draw.circle(screen, (0, 0, 255), (int(pos_x), int(pos_y)), prey_radius)\n",
    "\n",
    "            predator = self.predator_agent\n",
    "            pos_x, pos_y = predator.current_position\n",
    "            predator_radius = 10\n",
    "\n",
    "            pygame.draw.circle(screen, (255, 0, 0), (int(pos_x), int(pos_y)), predator_radius)\n",
    "\n",
    "            pygame.display.update()\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GameEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0]\n"
     ]
    }
   ],
   "source": [
    "action = str(30).zfill(2)\n",
    "digit1 = int(action[0]) % 4\n",
    "digit2 = int(action[1]) % 4\n",
    "action = [digit1, digit2]\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "done = False\n",
    "number_of_prey = 2\n",
    "number_of_predator = 3\n",
    "\n",
    "env.set_agent_number(prey_number=number_of_prey, predator_number=number_of_predator)\n",
    "env.agent_init()\n",
    "env.reset()\n",
    "\n",
    "while not done:\n",
    "    prey_action = []\n",
    "    predator_action = []\n",
    "    for i in range(0, number_of_prey):\n",
    "        prey_action.append(env.action_space.sample())\n",
    "    \n",
    "    for i in range(0, number_of_predator):\n",
    "        predator_action.append(env.action_space.sample())\n",
    "\n",
    "    action = [prey_action, predator_action]\n",
    "\n",
    "    obs, reward, done, _, _ = env.step(action)\n",
    "    print(obs)\n",
    "    # env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward: -30.0\n",
      "Number of steps: 30203\n"
     ]
    }
   ],
   "source": [
    "env = GameEnv()\n",
    "done = False\n",
    "\n",
    "env.agent_init()\n",
    "env.reset()\n",
    "total_reward = 0\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, _, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "print(f'total reward: {total_reward}')\n",
    "print(f'Number of steps: {env.total_steps}')\n",
    "    # env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([286.70355, 177.60149, 230.14369, 314.30106], dtype=float32), 0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = GameEnv()\n",
    "# number_of_prey = 2\n",
    "# number_of_predator = 3\n",
    "\n",
    "# env.set_agent_number(prey_number=number_of_prey, predator_number=number_of_predator)\n",
    "env.agent_init()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_path = os.path.join('Training', 'Models', 'test_baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -30      |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007848448 |\n",
      "|    clip_fraction        | 0.0683      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0192     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.000157    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006799057 |\n",
      "|    clip_fraction        | 0.0641      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0273     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.000101    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009037089 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0103      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.000117    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -30          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 252          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077183214 |\n",
      "|    clip_fraction        | 0.0805       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0164      |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0157      |\n",
      "|    value_loss           | 6.46e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008535825 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0413     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 6.09e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011418205 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0277     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 7.09e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008781873 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000438    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 5.35e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009767715 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0337     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    value_loss           | 5.15e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011839413 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0355     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    value_loss           | 5.1e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 257         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009738555 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.04       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 4e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 257         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009551322 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0038     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    value_loss           | 3.03e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 257         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011898706 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 3.03e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011756938 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0199      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 3.36e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -30          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 118          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085548535 |\n",
      "|    clip_fraction        | 0.0919       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0456      |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    value_loss           | 2.5e-05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -30          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 259          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113378465 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0467      |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0192      |\n",
      "|    value_loss           | 2.49e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -30          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 259          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 134          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0138064455 |\n",
      "|    clip_fraction        | 0.169        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.038       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.02        |\n",
      "|    value_loss           | 1.93e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011754382 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0195     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    value_loss           | 1.82e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 260         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012071902 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0187     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    value_loss           | 1.59e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 260         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009484761 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0265     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 1.98e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 260         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014530089 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0455     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    value_loss           | 1.68e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 260         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011010973 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.999      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0401     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 1.41e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -30          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 260          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108290175 |\n",
      "|    clip_fraction        | 0.098        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.989       |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0333      |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 1.26e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 261         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010226136 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00106     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 1.29e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 261         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011461478 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.973      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0297     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 9.83e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 261         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012644911 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.924      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0215     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 8.08e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 260         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015288362 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0316     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 9.84e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010890916 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.917      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0538     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    value_loss           | 6.42e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016453492 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.877      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0178     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 6.74e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012039775 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.894      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0378     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 6.15e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012735433 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.892      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0138     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    value_loss           | 5.88e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012821373 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.829      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0275     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    value_loss           | 1.41e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013718158 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0198     |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    value_loss           | 4.26e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015673194 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.802      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0528     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 6.65e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011859141 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.797      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0236     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 3.78e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 284         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010430757 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.795      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00991    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 5.25e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012664443 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.781      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00846    |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 3.61e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | -30          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 259          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 300          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0145409405 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.773       |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0408      |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0212      |\n",
      "|    value_loss           | 5.36e-06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 308         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012849616 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.788      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0291     |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 3.39e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011817941 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00303    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 2.92e-06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | -30        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 258        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 325        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01389683 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.766     |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0212    |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0215    |\n",
      "|    value_loss           | 3.31e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 257         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 333         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013782938 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.719      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0545     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    value_loss           | 3.4e-06     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 257         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013530236 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.717      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.022      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    value_loss           | 1.02e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | -30        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 257        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 349        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01339839 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.728     |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0307    |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0209    |\n",
      "|    value_loss           | 4.92e-06   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | -30        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 258        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 357        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01813396 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.654     |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0141    |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | -0.0198    |\n",
      "|    value_loss           | 2.53e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013176392 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0231     |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    value_loss           | 1.45e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012027744 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.591      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0123      |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 2.3e-06     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012673704 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.588      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0379     |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    value_loss           | 2.56e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 387         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011621195 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.598      |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0194     |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 4.23e-06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x129ee2c8690>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
