{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main import\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "\n",
    "from gymnasium import spaces\n",
    "from gymnasium.utils import seeding\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "import copy\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from ..utils.action_space import MultiAgentActionSpace\n",
    "from ..utils.draw import draw_grid, fill_cell, write_cell_text\n",
    "from ..utils.observation_space import MultiAgentObservationSpace \n",
    "\"\"\"\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Multi Agent Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgentActionSpace(list):\n",
    "    def __init__(self, agents_action_space):\n",
    "        # * checking if all the instances that go through here are of same classes or not\n",
    "        for x in agents_action_space:\n",
    "            assert isinstance(x, gym.spaces.space.Space)\n",
    "\n",
    "        super(MultiAgentActionSpace, self).__init__(agents_action_space)\n",
    "        self._agents_action_space = agents_action_space\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"samples action for each agents from uniform distribution\"\"\"\n",
    "        return [agents_action_space.sample() for agents_action_space in self._agents_action_space] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Multi Agent Obsercations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgentObservationSpace(list):\n",
    "    def __init__(self, agent_observation_space):\n",
    "        # * checking if all the instances that go through here are of same classes or not\n",
    "        for x in agent_observation_space:\n",
    "            assert isinstance(x. gym.spaces.space.Space)\n",
    "\n",
    "        super().__init__(agent_observation_space)\n",
    "        self._agents_observation_space = agent_observation_space\n",
    "\n",
    "    def sample(self):\n",
    "        return [agent_observation_space.sample() for agent_observation_space in self._agents_observation_space]\n",
    "\n",
    "    def contains(self, obs):\n",
    "        \"\"\"contains the obsercation of all the agents\"\"\"\n",
    "        for space, obs in zip(self._agents_observation_space, obs):\n",
    "            if not space.contains(obs):\n",
    "                return False\n",
    "            else:\n",
    "                return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Agent:\n",
    "    def __init__(self, agent_name, agent_index):\n",
    "        # identity\n",
    "        self.index = agent_index\n",
    "        self.agent = agent_name\n",
    "\n",
    "        # additional attributes\n",
    "        self.health = None\n",
    "        self.isHit = False\n",
    "        self.move = True\n",
    "        self.movement_speed = 1.00\n",
    "\n",
    "        # positional attributes\n",
    "        self.previous_position = np.array([0, 0], dtype=np.float32)\n",
    "        self.current_position = None\n",
    "        self.same_position = False\n",
    "\n",
    "        self.current_step = 0\n",
    "        self.action = None\n",
    "\n",
    "        # these are for the angular motion of the agent\n",
    "        self.angle = 0\n",
    "        self.center = 0\n",
    "        self.direction = 0\n",
    "        self.direction_end = 0\n",
    "\n",
    "        # this is custom only for the render function\n",
    "        self.draw_direction_end = 0\n",
    "\n",
    "    # for handling what the action does\n",
    "    def agent_action(self, action):\n",
    "        pass\n",
    "\n",
    "    # for handling all the initial states\n",
    "    def agent_reset(self, width, height):\n",
    "        padding = 30\n",
    "        # updating the initial random position of the agent at 1st\n",
    "        self.current_position = np.array(\n",
    "            [np.random.uniform(30, width - padding), np.random.uniform(30, height - padding)],\n",
    "            dtype=np.float32)\n",
    "\n",
    "        # updating the initial orientation to 0 degree at 1st\n",
    "        theta = math.radians(self.angle)\n",
    "        magnitude = padding\n",
    "        # this is for the trigonometry function X and Y\n",
    "        dir_vec_x = magnitude * math.cos(theta)\n",
    "        dir_vec_y = magnitude * math.sin(theta)\n",
    "        \n",
    "        # adding the direction vector to the center and get an end point for direction\n",
    "        self.direction_end = np.array([self.current_position[0] + dir_vec_x, self.current_position[1] + dir_vec_y],\n",
    "                                      dtype=np.float32)\n",
    "        \n",
    "        # this part is only for the render function\n",
    "        self.draw_direction_end = (self.current_position[0] + dir_vec_x, self.current_position[1] + dir_vec_y)\n",
    "\n",
    "    # updating the direction, line-end according to given angle when called\n",
    "    def get_direction(self):\n",
    "        # as render function demands an int value \n",
    "        center = (int(self.current_position[0]), int(self.current_position[1]))\n",
    "        self.center = center\n",
    "        \n",
    "        # the X, Y angular equation\n",
    "        theta = math.radians(self.angle)\n",
    "        magnitude = 30\n",
    "        # here is the X=cos()\n",
    "        directional_vector_x = magnitude * math.cos(theta)\n",
    "        # here is the Y=sin()\n",
    "        directional_vector_y = magnitude * math.sin(theta)\n",
    "\n",
    "        directional_line_end = np.array([center[0] + directional_vector_x, center[1] + directional_vector_y],\n",
    "                                        dtype=np.float32)\n",
    "        self.direction_end = directional_line_end\n",
    "        \n",
    "        direction = directional_line_end - center\n",
    "        direction /= np.linalg.norm(direction)\n",
    "        self.direction = direction\n",
    "        self.draw_direction_end = (center[0] + directional_vector_x, center[1] + directional_vector_y)\n",
    "\n",
    "    # for updating the states of the agent when called\n",
    "    def step_update(self, action, range_x, range_y):\n",
    "\n",
    "        # ! if used directional rotational movement\n",
    "        # rotate clockwise\n",
    "        if action == 0:\n",
    "\n",
    "            self.angle += 10\n",
    "            self.angle = self.angle % 360\n",
    "            # self.get_direction()\n",
    "\n",
    "        # rotate anti-clockwise\n",
    "        elif action == 1:\n",
    "            self.angle -= 10\n",
    "            self.angle = self.angle % 360\n",
    "            # self.get_direction()\n",
    "\n",
    "        # move front\n",
    "        elif action == 2:\n",
    "            self.current_position = self.current_position + self.direction * self.movement_speed\n",
    "            # self.get_direction()\n",
    "\n",
    "        # move back\n",
    "        elif action == 3:\n",
    "            self.current_position = self.current_position - self.direction * self.movement_speed\n",
    "            # self.get_direction()\n",
    "\n",
    "        # do nothing / wait\n",
    "        elif action == 4:\n",
    "            pass\n",
    "\n",
    "        self.get_direction()\n",
    "\n",
    "        self.current_position[0] = np.clip(self.current_position[0], 0, range_x)\n",
    "        self.current_position[1] = np.clip(self.current_position[1], 0, range_y)\n",
    "\n",
    "    # this function returns all the state needed for the observations\n",
    "    # ! can be changed with need for the algorithm\n",
    "    def get_agent_state(self):\n",
    "        \n",
    "        agent_state = {\n",
    "            'agent_id': self.index,\n",
    "            'agent_name': self.agent,\n",
    "            'agent_move_speed': self.movement_speed,\n",
    "            'agent_current_position': self.current_position,\n",
    "            'agent_angle': self.angle\n",
    "        }\n",
    "\n",
    "        return agent_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgentEnv(gym.Env):\n",
    "    metadata = {'render_mode':['human', 'rgb_array']}\n",
    "\n",
    "    def __init__(self, n_prey=1, n_predator=1):\n",
    "        # defining the screen size (observation render size)\n",
    "        self.screen_width = 400\n",
    "        self.screen_height = 400\n",
    "\n",
    "        # initiating the number of predators and preys\n",
    "        self._n_prey = n_prey\n",
    "        self._n_predator = n_predator\n",
    "\n",
    "        self.n_agents = n_prey + n_predator\n",
    "\n",
    "        # defining the action spaces for all the agents\n",
    "        self.action_space = MultiAgentActionSpace(\n",
    "            [spaces.Discrete(4) for _ in range(self.n_agents)]\n",
    "        )\n",
    "\n",
    "        # initiating prey agents' positions\n",
    "        self.prey_pos = {_ : None for _ in range(self._n_prey)}\n",
    "        self.prey_prev_pos = {_ : None for _ in range(self._n_prey)}\n",
    "\n",
    "        # initiating predator agents' positions\n",
    "        self.predator_pos = {_ : None for _ in range(self._n_predator)}\n",
    "        self.predator_prev_pos = {_ : None for _ in range(self._n_predator)}\n",
    "\n",
    "        # initiating their completion state\n",
    "        self.prey_dones = [None for _ in range(self._n_prey)]\n",
    "        self.predator_dones = [None for _ in range(self._n_predator)]\n",
    "\n",
    "        self._total_episode_reward = None\n",
    "        self.viewer = None\n",
    "        \n",
    "        # defining the observation space for all agents\n",
    "        self.observation_space = MultiAgentObservationSpace(\n",
    "            [spaces.Box() for _ in range(self.n_agents)]\n",
    "        )\n",
    "\n",
    "    def reset(self, seed=0):\n",
    "        pass\n",
    "\n",
    "    def step(self, action):\n",
    "        pass\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
