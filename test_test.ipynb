{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pygame\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Dict, Box, MultiDiscrete, Tuple\n",
    "\n",
    "from Agents.agent import Agent\n",
    "# from Agents.fov_points import get_fov_points\n",
    "# from Agents.overlap_detection import detect_overlapping_points\n",
    "from Agents.RayCast import get_fov_rays\n",
    "from Constants.constants import WHITE, RED, BLUE, SCREEN_WIDTH, SCREEN_HEIGHT, WALLS, WALLS2, FOV_RADIUS\n",
    "from Walls.collision_detection import detect_collision\n",
    "from Walls.wall_class import Walls\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameEnv(Env):\n",
    "    def __init__(self, render_mode='human'):\n",
    "        super(GameEnv, self).__init__()\n",
    "\n",
    "        # defining the screen dimension for render purpose\n",
    "        self.screen_width = SCREEN_WIDTH\n",
    "        self.screen_height = SCREEN_HEIGHT\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        # point_spaces = [Discrete(2) for _ in range(360)]\n",
    "\n",
    "        # dict1 = {\n",
    "        #     'predator_position': Box(low=np.array([0, 0], dtype=np.float32),\n",
    "        #                              high=np.array([SCREEN_WIDTH, SCREEN_HEIGHT], dtype=np.float32),\n",
    "        #                              dtype=np.float32),\n",
    "        #     'predator_angle': Discrete(360),\n",
    "        # }\n",
    "\n",
    "        # self.fov_points = {\n",
    "        #     f'point{point}': Tuple((Box(low=np.array([0, 0], dtype=np.float32),\n",
    "        #                              high=np.array([SCREEN_WIDTH, SCREEN_HEIGHT], dtype=np.float32),\n",
    "        #                              dtype=np.float32), Discrete(2))) for point in range(360)\n",
    "        # }\n",
    "\n",
    "        # custom_obs_space = {**dict1, **self.fov_points}\n",
    "        total_values = 219\n",
    "        self.observation_space = Box(low=np.zeros(total_values, dtype=np.float32), \n",
    "                                    high=self.screen_width * np.ones(total_values, dtype=np.float32), \n",
    "                                    dtype=np.float32)\n",
    "        # defining the observation and action spaces for all the agents\n",
    "        # self.observation_space = None\n",
    "\n",
    "        # defining the action space based on total number of predator and prey\n",
    "        # since we are training only one agent so, defining only the necessary number of actions\n",
    "        self.action_space = Discrete(5)\n",
    "        # 5 for rotate\n",
    "        # clockwise, anti-clock\n",
    "        # move front, move back and wait\n",
    "\n",
    "        self.total_steps = 0\n",
    "\n",
    "        self.number_of_predator = 1\n",
    "\n",
    "        self.predator_agent = None\n",
    "\n",
    "        self.predator_total_reward = 0\n",
    "\n",
    "        self.obs = None\n",
    "\n",
    "        # start the tick timer\n",
    "        self.start_time = 0\n",
    "        self.total_running_time = 10\n",
    "\n",
    "        # the pygame window should be initialized in the render function\n",
    "        # initializing the pygame\n",
    "        pygame.init()\n",
    "\n",
    "        # setting the screen size\n",
    "        self.screen = pygame.display.set_mode((self.screen_width, self.screen_height))\n",
    "        pygame.display.set_caption('Multi Agent Environment(simple)')\n",
    "\n",
    "        # initializing the font\n",
    "        pygame.font.init()\n",
    "        self.font = pygame.font.Font(None, 18)\n",
    "\n",
    "        # for the wall initializations\n",
    "        self.wall = Walls(pygame)\n",
    "        self.walls = None\n",
    "\n",
    "    def agent_init(self):\n",
    "        predator_agents = Agent('predator', 0)\n",
    "\n",
    "        self.predator_agent = predator_agents\n",
    "\n",
    "    def flatten_list(self, nested_list):\n",
    "        flattened_list = []\n",
    "        for item in nested_list:\n",
    "            if isinstance(item, list) :\n",
    "                flattened_list.extend(self.flatten_list(item))\n",
    "            else:\n",
    "                flattened_list.append(item)\n",
    "        return flattened_list\n",
    "    \n",
    "    def _get_obs(self):\n",
    "        # obs1= {\n",
    "        #     'predator_position': self.predator_agent.current_position,\n",
    "        #     'predator_angle': self.predator_agent.angle,    \n",
    "        # }\n",
    "        # value_list = detect_overlapping_points(self.predator_agent.current_position, WALLS)\n",
    "        \n",
    "        # obs2 = {f'point{index}': value for index, (_, value) in enumerate(value_list)}\n",
    "\n",
    "        # observation = {**obs1, **obs2}\n",
    "        observation = []\n",
    "        agent_pos = [self.predator_agent.current_position[0], self.predator_agent.current_position[1]]\n",
    "        observation.append(agent_pos)\n",
    "\n",
    "        angle = self.predator_agent.angle\n",
    "        observation.append(angle)\n",
    "\n",
    "        # value_list = detect_overlapping_points(self.predator_agent.current_position, WALLS)\n",
    "        value_list = get_fov_rays(agent_pos)\n",
    "        observation.append(value_list)\n",
    "        \n",
    "        observation = self.flatten_list(observation)\n",
    "        # print(observation)\n",
    "        return observation\n",
    "\n",
    "    def _max_right(self):\n",
    "        max_right = 0\n",
    "\n",
    "        for wall in self.walls:\n",
    "            if wall.right > max_right:\n",
    "                max_right = wall.right\n",
    "        \n",
    "        return max_right\n",
    "\n",
    "    def get_reward(self, reward):\n",
    "        reward = reward\n",
    "\n",
    "        # for wall in self.walls:\n",
    "        #     if wall.left - self.predator_agent.current_position[0] + self.predator_agent.radius < 2:\n",
    "        #         reward -= 10\n",
    "        #         print(f'less than wall left pred: {self.predator_agent.current_position[0] + self.predator_agent.radius}, wall: {wall.left}')\n",
    "        #     if self.predator_agent.current_position[0] + self.predator_agent.radius > wall.left \\\n",
    "        #         and self.predator_agent.current_position[0] - self.predator_agent.radius > wall.right:\n",
    "        #         if self.predator_agent.current_position[0] - self.predator_agent.radius - wall.right  < 2:\n",
    "        #             reward -= 10\n",
    "        #             print(f'less than wall right pred: {self.predator_agent.current_position[0] + self.predator_agent.radius}, wall: {wall.right}')\n",
    "\n",
    "        #     if self.predator_agent.current_position[0] + self.predator_agent.radius > wall.left \\\n",
    "        #         and self.predator_agent.current_position[0] + self.predator_agent.radius < wall.right:\n",
    "        #         reward += 50\n",
    "        # print(f'midtop: {self.walls[0].midtop}, midbottom: {self.walls[1].midbottom}')\n",
    "        mid_point = (np.array(self.walls[0].midbottom, dtype=np.float32)  + np.array(self.walls[1].midtop, dtype=np.float32)) / 2\n",
    "        # print(f'mid point: {mid_point}')\n",
    "        direction = mid_point - self.predator_agent.current_position\n",
    "        \n",
    "        # here goes a proximal reward function to maximize any trial of getting close to the goal\n",
    "        distance = np.linalg.norm(direction)\n",
    "        if self.predator_agent.current_position[0] < mid_point[0]:\n",
    "            reward += (1/distance)\n",
    "\n",
    "        # print(f'direction: {direction}, distance:{distance}, reward: {reward}')\n",
    "        return reward\n",
    "\n",
    "\n",
    "\n",
    "    # the usual reset function\n",
    "    def reset(self, seed=0):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "        self.agent_init()\n",
    "        self.wall.clear_walls()\n",
    "        self.walls = self.wall.make_wall(WALLS2)\n",
    "\n",
    "        # self.set_obs_space()\n",
    "\n",
    "        self.total_steps = 0\n",
    "        self.predator_total_reward = 0\n",
    "\n",
    "        predator = self.predator_agent\n",
    "\n",
    "        # for predator in self.predator_agents:\n",
    "        predator.agent_reset(width=self.screen_width, height=self.screen_height, walls=self.walls)\n",
    "        # observation.append([predator.index, predator.agent, predator.current_position])\n",
    "\n",
    "        # setting the predator and prey to their initial position\n",
    "\n",
    "        self.predator_agent = predator\n",
    "\n",
    "\n",
    "        # all the variable values inside the observation space needs to be sent inside the observation variable\n",
    "        # for this level purpose we decided to add the dictionary observation\n",
    "        # set the observation to a dictionary\n",
    "        observation = self._get_obs()\n",
    "        self.obs = observation\n",
    "\n",
    "        return observation, seed\n",
    "\n",
    "    def step(self, action):\n",
    "        # initializing the return variables\n",
    "        done = False\n",
    "        reward = 0\n",
    "        truncated = False\n",
    "        info = {}\n",
    "        current_time = time.time()\n",
    "\n",
    "        elapsed_time = current_time - self.start_time\n",
    "        # handles the pygame window event when closing\n",
    "        # !if the window still crashes pygame.event needs to be managed properly\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                done = True\n",
    "                pygame.quit()\n",
    "        self.predator_agent.step_update(action, range_x=self.screen_width, range_y=self.screen_height)\n",
    "        self.predator_agent = detect_collision(self.predator_agent, self.walls)\n",
    "\n",
    "        # observation needs to be set a dictionary\n",
    "\n",
    "        self.total_steps += 1\n",
    "        # reward = self.get_reward(reward)\n",
    "        # for wall in self.walls:\n",
    "        if self.predator_agent.current_position[0] > self._max_right():\n",
    "            reward += 150\n",
    "            done = True\n",
    "\n",
    "        # if elapsed_time >= self.total_running_time:\n",
    "        #     reward -= 50\n",
    "        #     done = True\n",
    "        \"\"\"\n",
    "        here lies the most important task\n",
    "        handling the rewards\n",
    "        \"\"\"\n",
    "        reward += 0.01\n",
    "        self.render()\n",
    "\n",
    "        # it will update the total reward every step\n",
    "        observation = self._get_obs()\n",
    "        self.predator_total_reward = reward\n",
    "        self.obs = observation\n",
    "\n",
    "        return observation, reward, done, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == 'human':\n",
    "            screen = self.screen\n",
    "\n",
    "            screen.fill(WHITE)\n",
    "            predator = self.predator_agent\n",
    "            pygame.draw.circle(screen, RED, predator.center, predator.radius)\n",
    "            pygame.draw.line(screen, RED, predator.center, predator.draw_direction_end, 5)\n",
    "\n",
    "            for key, wall in WALLS2.items():\n",
    "                pygame.draw.rect(screen, BLUE, (wall['x'], wall['y'], wall['width'], wall['height']))\n",
    "\n",
    "            text_surface = self.font.render(f\"Reward: {self.predator_total_reward: .5f} \", True, (0, 0, 0))\n",
    "\n",
    "            text_rect = text_surface.get_rect()\n",
    "\n",
    "            text_rect.center = (self.screen_width - 200, 10)\n",
    "\n",
    "            self.screen.blit(text_surface, text_rect)\n",
    "\n",
    "            pygame.display.update()\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GameEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32md:\\CSE465_PROJECT\\CSE_465\\test_test.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     action \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39msample()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     _, _, done, _, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n",
      "\u001b[1;32md:\\CSE465_PROJECT\\CSE_465\\test_test.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=210'>211</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=211'>212</a>\u001b[0m \u001b[39mhere lies the most important task\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=212'>213</a>\u001b[0m \u001b[39mhandling the rewards\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=213'>214</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=214'>215</a>\u001b[0m reward \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=215'>216</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=217'>218</a>\u001b[0m \u001b[39m# it will update the total reward every step\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=218'>219</a>\u001b[0m observation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_obs()\n",
      "\u001b[1;32md:\\CSE465_PROJECT\\CSE_465\\test_test.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=225'>226</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=226'>227</a>\u001b[0m     screen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscreen\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=228'>229</a>\u001b[0m     screen\u001b[39m.\u001b[39;49mfill(WHITE)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=229'>230</a>\u001b[0m     predator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredator_agent\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CSE465_PROJECT/CSE_465/test_test.ipynb#W4sZmlsZQ%3D%3D?line=230'>231</a>\u001b[0m     pygame\u001b[39m.\u001b[39mdraw\u001b[39m.\u001b[39mcircle(screen, RED, predator\u001b[39m.\u001b[39mcenter, predator\u001b[39m.\u001b[39mradius)\n",
      "\u001b[1;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    _, _, done, _, _ = env.step(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs', 'Level_01_DQN')\n",
    "baseline_path = os.path.join('Training', 'Models', 'Level_01_DQN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN('MlpPolicy', env, verbose=1, tensorboard_log=log_path )\n",
    "env.reset()\n",
    "model.learn(total_timesteps=2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
