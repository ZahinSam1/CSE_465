{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pygame\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Dict, Box\n",
    "\n",
    "from Agents.agent import Agent\n",
    "# from Agents.fov_points import get_fov_points\n",
    "from Agents.overlap_detection import detect_overlapping_points\n",
    "from Constants.constants import WHITE, RED, BLUE, SCREEN_WIDTH, SCREEN_HEIGHT, WALLS, FOV_RADIUS\n",
    "from Walls.collision_detection import detect_collision\n",
    "from Walls.wall_class import Walls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameEnv(Env):\n",
    "    def __init__(self, render_mode='human'):\n",
    "        super(GameEnv, self).__init__()\n",
    "\n",
    "        # defining the screen dimension for render purpose\n",
    "        self.screen_width = SCREEN_WIDTH\n",
    "        self.screen_height = SCREEN_HEIGHT\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        # defining the observation and action spaces for all the agents\n",
    "        self.observation_space = Dict({\n",
    "            'predator_position': Box(low=np.array([0, 0], dtype=np.float32),\n",
    "                                     high=np.array([SCREEN_WIDTH, SCREEN_HEIGHT], dtype=np.float32),\n",
    "                                     dtype=np.float32),\n",
    "            'vision': Dict({\n",
    "                'vision_points': Discrete(2)\n",
    "            }),\n",
    "        })\n",
    "\n",
    "        # defining the action space based on total number of predator and prey\n",
    "        # since we are training only one agent so, defining only the necessary number of actions\n",
    "        self.action_space = Discrete(5)\n",
    "        # 5 for rotate\n",
    "        # clockwise, anti-clock\n",
    "        # move front, move back and wait\n",
    "\n",
    "        self.total_steps = 0\n",
    "\n",
    "        self.number_of_predator = 1\n",
    "\n",
    "        self.predator_agent = None\n",
    "\n",
    "        self.predator_total_reward = 0\n",
    "\n",
    "        self.obs = None\n",
    "\n",
    "        # start the tick timer\n",
    "        self.start_time = 0\n",
    "        self.total_running_time = 10\n",
    "\n",
    "        # the pygame window should be initialized in the render function\n",
    "        # initializing the pygame\n",
    "        pygame.init()\n",
    "\n",
    "        # setting the screen size\n",
    "        self.screen = pygame.display.set_mode((self.screen_width, self.screen_height))\n",
    "        pygame.display.set_caption('Multi Agent Environment(simple)')\n",
    "\n",
    "        # initializing the font\n",
    "        pygame.font.init()\n",
    "        self.font = pygame.font.Font(None, 18)\n",
    "\n",
    "        # for the wall initializations\n",
    "        self.wall = Walls(pygame)\n",
    "        self.walls = None\n",
    "\n",
    "    def agent_init(self):\n",
    "        predator_agents = Agent('predator', 0)\n",
    "\n",
    "        self.predator_agent = predator_agents\n",
    "\n",
    "    def _get_obs(self):\n",
    "        observation = {\n",
    "            'predator_position': self.predator_agent.current_position,\n",
    "            'predator_angle': self.predator_agent.angle,\n",
    "            'vision': detect_overlapping_points(self.predator_agent.current_position, WALLS),\n",
    "        }\n",
    "\n",
    "        return observation\n",
    "\n",
    "    def _max_right(self):\n",
    "        max_right = 0\n",
    "\n",
    "        for wall in self.walls:\n",
    "            if wall.right > max_right:\n",
    "                max_right = wall.right\n",
    "        return max_right\n",
    "\n",
    "    # the usual reset function\n",
    "    def reset(self, seed=0):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "        self.agent_init()\n",
    "        self.wall.clear_walls()\n",
    "        self.walls = self.wall.make_wall(WALLS)\n",
    "\n",
    "        self.total_steps = 0\n",
    "        self.predator_total_reward = 0\n",
    "\n",
    "        predator = self.predator_agent\n",
    "\n",
    "        # for predator in self.predator_agents:\n",
    "        predator.agent_reset(width=self.screen_width, height=self.screen_height, walls=self.walls)\n",
    "        # observation.append([predator.index, predator.agent, predator.current_position])\n",
    "\n",
    "        # setting the predator and prey to their initial position\n",
    "\n",
    "        self.predator_agent = predator\n",
    "\n",
    "\n",
    "        # all the variable values inside the observation space needs to be sent inside the observation variable\n",
    "        # for this level purpose we decided to add the dictionary observation\n",
    "        # set the observation to a dictionary\n",
    "        observation = self._get_obs()\n",
    "        self.obs = observation\n",
    "\n",
    "        return observation, seed\n",
    "\n",
    "    def step(self, action):\n",
    "        # initializing the return variables\n",
    "        done = False\n",
    "        reward = 0\n",
    "        truncated = False\n",
    "        info = {}\n",
    "        current_time = time.time()\n",
    "\n",
    "        elapsed_time = current_time - self.start_time\n",
    "        # handles the pygame window event when closing\n",
    "        # !if the window still crashes pygame.event needs to be managed properly\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                done = True\n",
    "                pygame.quit()\n",
    "        self.predator_agent.step_update(action, range_x=self.screen_width, range_y=self.screen_height)\n",
    "        self.predator_agent = detect_collision(self.predator_agent, self.walls)\n",
    "\n",
    "        # observation needs to be set a dictionary\n",
    "\n",
    "        self.total_steps += 1\n",
    "        print(self._max_right())\n",
    "        # for wall in self.walls:\n",
    "        if self.predator_agent.current_position[0] > self._max_right():\n",
    "            reward += 100\n",
    "            done = True\n",
    "\n",
    "        if elapsed_time >= self.total_running_time:\n",
    "            done = True\n",
    "        \"\"\"\n",
    "        here lies the most important task\n",
    "        handling the rewards\n",
    "        \"\"\"\n",
    "        reward += 0.01\n",
    "        self.render()\n",
    "\n",
    "        # it will update the total reward every step\n",
    "        observation = self._get_obs()\n",
    "        self.predator_total_reward = reward\n",
    "        self.obs = observation\n",
    "\n",
    "        return observation, reward, done, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == 'human':\n",
    "            screen = self.screen\n",
    "\n",
    "            screen.fill(WHITE)\n",
    "            predator = self.predator_agent\n",
    "            pygame.draw.circle(screen, RED, predator.center, predator.radius)\n",
    "            pygame.draw.line(screen, RED, predator.center, predator.draw_direction_end, 5)\n",
    "\n",
    "            for key, wall in WALLS.items():\n",
    "                pygame.draw.rect(screen, BLUE, (wall['x'], wall['y'], wall['width'], wall['height']))\n",
    "\n",
    "            pygame.display.update()\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GameEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs', 'Level_01')\n",
    "baseline_path = os.path.join('Training', 'Models', 'Level_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
