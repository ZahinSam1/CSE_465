{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bresenham'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\jupyter\\Reinforcement Learning\\CSE_465\\test.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/jupyter/Reinforcement%20Learning/CSE_465/test.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgymnasium\u001b[39;00m \u001b[39mimport\u001b[39;00m Env\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/jupyter/Reinforcement%20Learning/CSE_465/test.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgymnasium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspaces\u001b[39;00m \u001b[39mimport\u001b[39;00m Discrete, Dict, Box, MultiDiscrete, Tuple\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/jupyter/Reinforcement%20Learning/CSE_465/test.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbresenham\u001b[39;00m \u001b[39mimport\u001b[39;00m bresenham\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jupyter/Reinforcement%20Learning/CSE_465/test.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mAgents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magent\u001b[39;00m \u001b[39mimport\u001b[39;00m Agent\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jupyter/Reinforcement%20Learning/CSE_465/test.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# from Agents.fov_points import get_fov_points\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jupyter/Reinforcement%20Learning/CSE_465/test.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# from Agents.overlap_detection import detect_overlapping_points\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bresenham'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pygame\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Dict, Box, MultiDiscrete, Tuple\n",
    "\n",
    "from Agents.agent import Agent\n",
    "# from Agents.fov_points import get_fov_points\n",
    "# from Agents.overlap_detection import detect_overlapping_points\n",
    "from Agents.RayCast import get_fov_rays\n",
    "from Constants.constants import WHITE, RED, BLUE, SCREEN_WIDTH, SCREEN_HEIGHT, WALLS, WALLS2, FOV_RADIUS\n",
    "from Walls.collision_detection import detect_collision\n",
    "from Walls.wall_class import Walls\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameEnv(Env):\n",
    "    metadata = {\"render_modes\" : [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=None):\n",
    "        super(GameEnv, self).__init__()\n",
    "\n",
    "        # defining the screen dimension for render purpose\n",
    "        self.screen_width = SCREEN_WIDTH\n",
    "        self.screen_height = SCREEN_HEIGHT\n",
    "\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "\n",
    "        # total_values = 219\n",
    "        # self.observation_space = Box(low=np.zeros(total_values, dtype=np.float32), \n",
    "        #                             high=self.screen_width * np.ones(total_values, dtype=np.float32), \n",
    "        #                             dtype=np.float32)\n",
    "\n",
    "        self.observation_space = Dict({\n",
    "            \"predator_position\": Box(low=np.array([0, 0], dtype=np.float32),\n",
    "                                    high=np.array([self.screen_width, self.screen_height], dtype=np.float32),\n",
    "                                    dtype=np.float32),\n",
    "            \"predator_angle\": Discrete(360),\n",
    "            \"destination_coordinates\": Box(low=np.array([0, 0, 0, 0], dtype=np.float32),\n",
    "                                    high=np.array([self.screen_width, self.screen_height, self.screen_width, self.screen_height], dtype=np.float32),\n",
    "                                    dtype=np.float32),\n",
    "        })\n",
    "        # defining the observation and action spaces for all the agents\n",
    "        # self.observation_space = None\n",
    "\n",
    "        # defining the action space based on total number of predator and prey\n",
    "        # since we are training only one agent so, defining only the necessary number of actions\n",
    "        self.action_space = Discrete(3)\n",
    "        # 5 for rotate\n",
    "        # clockwise, anti-clock\n",
    "        # move front, move back and wait\n",
    "\n",
    "        self.total_steps = 0\n",
    "\n",
    "        self.number_of_predator = 1\n",
    "\n",
    "        self.predator_agent = None\n",
    "\n",
    "        self.predator_total_reward = 0\n",
    "\n",
    "        self.obs = None\n",
    "\n",
    "        # start the tick timer\n",
    "        self.start_time = 0\n",
    "        self.total_running_time = 10\n",
    "\n",
    "        # the pygame window should be initialized in the render function\n",
    "        # initializing the pygame\n",
    "        # pygame.init()\n",
    "\n",
    "        # # setting the screen size\n",
    "        # self.screen = pygame.display.set_mode((self.screen_width, self.screen_height))\n",
    "        # pygame.display.set_caption('Multi Agent Environment(simple)')\n",
    "\n",
    "        # # initializing the font\n",
    "        # pygame.font.init()\n",
    "        # self.font = pygame.font.Font(None, 18)\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "\n",
    "        # for the wall initializations\n",
    "        self.wall = Walls(pygame)\n",
    "        self.walls = None\n",
    "\n",
    "    def agent_init(self):\n",
    "        predator_agents = Agent('predator', 0)\n",
    "\n",
    "        self.predator_agent = predator_agents\n",
    "\n",
    "    def flatten_list(self, nested_list):\n",
    "        flattened_list = []\n",
    "        for item in nested_list:\n",
    "            if isinstance(item, list) :\n",
    "                flattened_list.extend(self.flatten_list(item))\n",
    "            else:\n",
    "                flattened_list.append(item)\n",
    "        return flattened_list\n",
    "    \n",
    "    def _get_obs(self):\n",
    "        \"\"\"\n",
    "        these are for the box observation\n",
    "        \"\"\"\n",
    "        # observation = []\n",
    "        # agent_pos = [self.predator_agent.current_position[0], self.predator_agent.current_position[1]]\n",
    "        # observation.append(agent_pos)\n",
    "\n",
    "        # angle = self.predator_agent.angle\n",
    "        # observation.append(angle)\n",
    "\n",
    "        # # value_list = detect_overlapping_points(self.predator_agent.current_position, WALLS)\n",
    "        # value_list = get_fov_rays(agent_pos)\n",
    "        # observation.append(value_list)\n",
    "        \n",
    "        # observation = self.flatten_list(observation)\n",
    "        \"\"\"\n",
    "        ends here\n",
    "        \"\"\"\n",
    "\n",
    "        end_point = (np.array(self.walls[0].bottomright) + np.array(self.walls[1].topright)) /2\n",
    "\n",
    "        top = np.array(self.walls[0].bottomright, dtype=np.float32)\n",
    "        bottom = np.array(self.walls[1].topright, dtype=np.float32)\n",
    "\n",
    "        observation = {\n",
    "            \"predator_position\": self.predator_agent.current_position,\n",
    "            \"predator_angle\": self.predator_agent.angle,\n",
    "            \"destination_coordinates\": np.concatenate([top, bottom]),\n",
    "        }\n",
    "\n",
    "        # print(observation)\n",
    "        return observation\n",
    "    \n",
    "    # to capture all the info\n",
    "    def _get_info(self):\n",
    "        mid_point = (np.array(self.walls[0].midbottom, dtype=np.float32)  + np.array(self.walls[1].midtop, dtype=np.float32)) / 2\n",
    "        # print(f'mid point: {mid_point}')\n",
    "        direction = mid_point - self.predator_agent.current_position\n",
    "        \n",
    "        # here goes a proximal reward function to maximize any trial of getting close to the goal\n",
    "        distance = np.linalg.norm(direction)\n",
    "        info = {\n",
    "            \"distance\": distance,\n",
    "        }\n",
    "\n",
    "        return info\n",
    "\n",
    "\n",
    "    def _max_right(self):\n",
    "        max_right = 0\n",
    "\n",
    "        for wall in self.walls:\n",
    "            if wall.right > max_right:\n",
    "                max_right = wall.right\n",
    "        \n",
    "        return max_right\n",
    "\n",
    "    def get_reward(self, reward):\n",
    "        reward = reward\n",
    "\n",
    "        # for wall in self.walls:\n",
    "        #     if wall.left - self.predator_agent.current_position[0] + self.predator_agent.radius < 2:\n",
    "        #         reward -= 10\n",
    "        #         print(f'less than wall left pred: {self.predator_agent.current_position[0] + self.predator_agent.radius}, wall: {wall.left}')\n",
    "        #     if self.predator_agent.current_position[0] + self.predator_agent.radius > wall.left \\\n",
    "        #         and self.predator_agent.current_position[0] - self.predator_agent.radius > wall.right:\n",
    "        #         if self.predator_agent.current_position[0] - self.predator_agent.radius - wall.right  < 2:\n",
    "        #             reward -= 10\n",
    "        #             print(f'less than wall right pred: {self.predator_agent.current_position[0] + self.predator_agent.radius}, wall: {wall.right}')\n",
    "\n",
    "        #     if self.predator_agent.current_position[0] + self.predator_agent.radius > wall.left \\\n",
    "        #         and self.predator_agent.current_position[0] + self.predator_agent.radius < wall.right:\n",
    "        #         reward += 50\n",
    "        # print(f'midtop: {self.walls[0].midtop}, midbottom: {self.walls[1].midbottom}')\n",
    "        mid_point = (np.array(self.walls[0].midbottom, dtype=np.float32)  + np.array(self.walls[1].midtop, dtype=np.float32)) / 2\n",
    "        # print(f'mid point: {mid_point}')\n",
    "        direction = mid_point - self.predator_agent.current_position\n",
    "        \n",
    "        # here goes a proximal reward function to maximize any trial of getting close to the goal\n",
    "        distance = np.linalg.norm(direction)\n",
    "        if self.predator_agent.current_position[0] < mid_point[0]:\n",
    "            reward += 1/distance\n",
    "\n",
    "        # print(f'direction: {direction}, distance:{distance}, reward: {reward}')\n",
    "        return reward\n",
    "\n",
    "\n",
    "    # the usual reset function\n",
    "    def reset(self, seed=None, option=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.start_time = time.time()\n",
    "\n",
    "        self.agent_init()\n",
    "        self.wall.clear_walls()\n",
    "        self.walls = self.wall.make_wall(WALLS2)\n",
    "\n",
    "        # self.set_obs_space()\n",
    "\n",
    "        self.total_steps = 0\n",
    "        self.predator_total_reward = 0\n",
    "\n",
    "        predator = self.predator_agent\n",
    "\n",
    "        # for predator in self.predator_agents:\n",
    "        predator.agent_reset(width=self.screen_width, height=self.screen_height, walls=self.walls)\n",
    "        # observation.append([predator.index, predator.agent, predator.current_position])\n",
    "\n",
    "        # setting the predator and prey to their initial position\n",
    "\n",
    "        self.predator_agent = predator\n",
    "\n",
    "\n",
    "        # all the variable values inside the observation space needs to be sent inside the observation variable\n",
    "        # for this level purpose we decided to add the dictionary observation\n",
    "        # set the observation to a dictionary\n",
    "        observation = self._get_obs()\n",
    "        self.obs = observation\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        # initializing the return variables\n",
    "        done = False\n",
    "        reward = 0\n",
    "        truncated = False\n",
    "        info = {}\n",
    "        current_time = time.time()\n",
    "\n",
    "        elapsed_time = current_time - self.start_time\n",
    "\n",
    "        self.predator_agent.step_update(action, range_x=self.screen_width, range_y=self.screen_height)\n",
    "        self.predator_agent = detect_collision(self.predator_agent, self.walls)\n",
    "\n",
    "        # observation needs to be set a dictionary\n",
    "\n",
    "        self.total_steps += 1\n",
    "        reward = self.get_reward(reward)\n",
    "        \n",
    "        # for wall in self.walls:\n",
    "        if self.predator_agent.current_position[0] > self._max_right():\n",
    "            reward += 200\n",
    "            done = True\n",
    "\n",
    "        if elapsed_time >= self.total_running_time + 5:\n",
    "            reward -= 100\n",
    "            done = True\n",
    "        \"\"\"\n",
    "        here lies the most important task\n",
    "        handling the rewards\n",
    "        \"\"\"\n",
    "        \n",
    "        # getting observation and info\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        self.predator_total_reward = reward\n",
    "        self.obs = observation\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, reward, done, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == 'rgb_array':\n",
    "            self._render_frame()\n",
    "\n",
    "\n",
    "    def _render_frame(self):\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode((self.screen_width, self.screen_height))\n",
    "            pygame.font.init()\n",
    "\n",
    "        if self.clock is None and self.render_mode == \"human\":\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        screen = pygame.Surface((self.screen_width, self.screen_height))\n",
    "        screen.fill(WHITE)\n",
    "        \n",
    "        predator = self.predator_agent\n",
    "        pygame.draw.circle(screen, RED, predator.center, predator.radius)\n",
    "        pygame.draw.line(screen, RED, predator.center, predator.draw_direction_end, 5)\n",
    "\n",
    "        for key, wall in WALLS2.items():\n",
    "            pygame.draw.rect(screen, BLUE, (wall['x'], wall['y'], wall['width'], wall['height']))\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "\n",
    "            font = pygame.font.Font(None, 18)\n",
    "        \n",
    "            text_surface = font.render(f\"Reward: {self.predator_total_reward: .5f} \", True, (0, 0, 0))\n",
    "\n",
    "            text_rect = text_surface.get_rect()\n",
    "\n",
    "            text_rect.center = (self.screen_width - 200, 10)\n",
    "            \n",
    "            screen.blit(text_surface, text_rect)\n",
    "            self.window.blit(screen, screen.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            # this part is to fix the fps of rendering\n",
    "            # self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        \n",
    "        else:\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(screen)), axes=(1, 0, 2)\n",
    "            )\n",
    "\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.font.quit()\n",
    "            pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GameEnv(render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'human'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "done = False\n",
    "traunc = False\n",
    "while not traunc:\n",
    "    action = env.action_space.sample()\n",
    "    _, _, done, traunc, _ = env.step(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs', 'Level_01_DQN')\n",
    "baseline_path = os.path.join('Training', 'Models', 'Level_01_DQN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = DQN('MultiInputPolicy', env, verbose=1, tensorboard_log=log_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\Level_01_DQN\\DQN_27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.52e+03 |\n",
      "|    ep_rew_mean      | -7.6     |\n",
      "|    exploration_rate | 0.955    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 258      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 14074    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.67e+03 |\n",
      "|    ep_rew_mean      | -43.1    |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 256      |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 29369    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.85e+03 |\n",
      "|    ep_rew_mean      | -55.7    |\n",
      "|    exploration_rate | 0.854    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 265      |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 46224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.64e+03 |\n",
      "|    ep_rew_mean      | -63.7    |\n",
      "|    exploration_rate | 0.815    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 248      |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total_timesteps  | 58274    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.97e-06 |\n",
      "|    n_updates        | 239568   |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# env.reset()\n",
    "model.learn(total_timesteps=3000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\Level_01_DQN\\DQN_22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.18e+03 |\n",
      "|    ep_rew_mean      | 104      |\n",
      "|    exploration_rate | 0.879    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 318      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 12740    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.19e+03 |\n",
      "|    ep_rew_mean      | 68       |\n",
      "|    exploration_rate | 0.757    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 319      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 25540    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.2e+03  |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.636    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 319      |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 38353    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.16e+03 |\n",
      "|    ep_rew_mean      | 47.6     |\n",
      "|    exploration_rate | 0.52     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 315      |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 50542    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000685 |\n",
      "|    n_updates        | 112635   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.93e+03 |\n",
      "|    ep_rew_mean      | 39.5     |\n",
      "|    exploration_rate | 0.444    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 292      |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 58534    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00283  |\n",
      "|    n_updates        | 114633   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.76e+03 |\n",
      "|    ep_rew_mean      | 29.4     |\n",
      "|    exploration_rate | 0.37     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 276      |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 66278    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00266  |\n",
      "|    n_updates        | 116569   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.63e+03 |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.301    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 262      |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total_timesteps  | 73621    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 118405   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.53e+03 |\n",
      "|    ep_rew_mean      | 16.8     |\n",
      "|    exploration_rate | 0.231    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 252      |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total_timesteps  | 80918    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00678  |\n",
      "|    n_updates        | 120229   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.44e+03 |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.164    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 244      |\n",
      "|    time_elapsed     | 360      |\n",
      "|    total_timesteps  | 87975    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00028  |\n",
      "|    n_updates        | 121993   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.37e+03 |\n",
      "|    ep_rew_mean      | 9.54     |\n",
      "|    exploration_rate | 0.0977   |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 237      |\n",
      "|    time_elapsed     | 400      |\n",
      "|    total_timesteps  | 94979    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00044  |\n",
      "|    n_updates        | 123744   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.32e+03 |\n",
      "|    ep_rew_mean      | 5.76     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 231      |\n",
      "|    time_elapsed     | 440      |\n",
      "|    total_timesteps  | 101977   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00477  |\n",
      "|    n_updates        | 125494   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.27e+03 |\n",
      "|    ep_rew_mean      | 3.53     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 226      |\n",
      "|    time_elapsed     | 480      |\n",
      "|    total_timesteps  | 108987   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 127246   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.23e+03 |\n",
      "|    ep_rew_mean      | 1.41     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 222      |\n",
      "|    time_elapsed     | 520      |\n",
      "|    total_timesteps  | 116008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0062   |\n",
      "|    n_updates        | 129001   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.2e+03  |\n",
      "|    ep_rew_mean      | -0.639   |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 219      |\n",
      "|    time_elapsed     | 560      |\n",
      "|    total_timesteps  | 122924   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00305  |\n",
      "|    n_updates        | 130730   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | -2.84    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 216      |\n",
      "|    time_elapsed     | 600      |\n",
      "|    total_timesteps  | 129896   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000357 |\n",
      "|    n_updates        | 132473   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | -4.66    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 213      |\n",
      "|    time_elapsed     | 640      |\n",
      "|    total_timesteps  | 136661   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 134165   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | -6.14    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 211      |\n",
      "|    time_elapsed     | 680      |\n",
      "|    total_timesteps  | 143589   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 135897   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | -7.43    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 208      |\n",
      "|    time_elapsed     | 720      |\n",
      "|    total_timesteps  | 150573   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000854 |\n",
      "|    n_updates        | 137643   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07e+03 |\n",
      "|    ep_rew_mean      | -8.77    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 207      |\n",
      "|    time_elapsed     | 760      |\n",
      "|    total_timesteps  | 157469   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000547 |\n",
      "|    n_updates        | 139367   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | -9.89    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 205      |\n",
      "|    time_elapsed     | 800      |\n",
      "|    total_timesteps  | 164373   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000762 |\n",
      "|    n_updates        | 141093   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | -10.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 203      |\n",
      "|    time_elapsed     | 840      |\n",
      "|    total_timesteps  | 171326   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000785 |\n",
      "|    n_updates        | 142831   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | -11.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 202      |\n",
      "|    time_elapsed     | 880      |\n",
      "|    total_timesteps  | 178141   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000851 |\n",
      "|    n_updates        | 144535   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | -11.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 201      |\n",
      "|    time_elapsed     | 920      |\n",
      "|    total_timesteps  | 185122   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000739 |\n",
      "|    n_updates        | 146280   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2e+03    |\n",
      "|    ep_rew_mean      | -12.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 199      |\n",
      "|    time_elapsed     | 960      |\n",
      "|    total_timesteps  | 192057   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000964 |\n",
      "|    n_updates        | 148014   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | -13.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 198      |\n",
      "|    time_elapsed     | 1000     |\n",
      "|    total_timesteps  | 198840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000923 |\n",
      "|    n_updates        | 149709   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.93e+03 |\n",
      "|    ep_rew_mean      | -18.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 197      |\n",
      "|    time_elapsed     | 1040     |\n",
      "|    total_timesteps  | 205665   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 151416   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.87e+03 |\n",
      "|    ep_rew_mean      | -20.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 196      |\n",
      "|    time_elapsed     | 1080     |\n",
      "|    total_timesteps  | 212418   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000732 |\n",
      "|    n_updates        | 153104   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | -23.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 195      |\n",
      "|    time_elapsed     | 1120     |\n",
      "|    total_timesteps  | 219239   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000954 |\n",
      "|    n_updates        | 154809   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.75e+03 |\n",
      "|    ep_rew_mean      | -25.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 194      |\n",
      "|    time_elapsed     | 1160     |\n",
      "|    total_timesteps  | 225902   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000924 |\n",
      "|    n_updates        | 156475   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -27.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 193      |\n",
      "|    time_elapsed     | 1200     |\n",
      "|    total_timesteps  | 232765   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 158191   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -27.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 193      |\n",
      "|    time_elapsed     | 1240     |\n",
      "|    total_timesteps  | 239704   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 159925   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -27.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 192      |\n",
      "|    time_elapsed     | 1280     |\n",
      "|    total_timesteps  | 246576   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000275 |\n",
      "|    n_updates        | 161643   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -27.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 191      |\n",
      "|    time_elapsed     | 1320     |\n",
      "|    total_timesteps  | 253461   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000884 |\n",
      "|    n_updates        | 163365   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.72e+03 |\n",
      "|    ep_rew_mean      | -28.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 191      |\n",
      "|    time_elapsed     | 1360     |\n",
      "|    total_timesteps  | 260373   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 165093   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.72e+03 |\n",
      "|    ep_rew_mean      | -28.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 190      |\n",
      "|    time_elapsed     | 1400     |\n",
      "|    total_timesteps  | 266847   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000341 |\n",
      "|    n_updates        | 166711   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.71e+03 |\n",
      "|    ep_rew_mean      | -28.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 189      |\n",
      "|    time_elapsed     | 1440     |\n",
      "|    total_timesteps  | 273153   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00041  |\n",
      "|    n_updates        | 168288   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.71e+03 |\n",
      "|    ep_rew_mean      | -29.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 188      |\n",
      "|    time_elapsed     | 1481     |\n",
      "|    total_timesteps  | 279724   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000435 |\n",
      "|    n_updates        | 169930   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.7e+03  |\n",
      "|    ep_rew_mean      | -29.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 188      |\n",
      "|    time_elapsed     | 1521     |\n",
      "|    total_timesteps  | 286259   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00094  |\n",
      "|    n_updates        | 171564   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.7e+03  |\n",
      "|    ep_rew_mean      | -30.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 187      |\n",
      "|    time_elapsed     | 1561     |\n",
      "|    total_timesteps  | 292812   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000192 |\n",
      "|    n_updates        | 173202   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.69e+03 |\n",
      "|    ep_rew_mean      | -30.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 186      |\n",
      "|    time_elapsed     | 1601     |\n",
      "|    total_timesteps  | 299211   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000313 |\n",
      "|    n_updates        | 174802   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.69e+03 |\n",
      "|    ep_rew_mean      | -30.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 186      |\n",
      "|    time_elapsed     | 1641     |\n",
      "|    total_timesteps  | 305633   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 176408   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.69e+03 |\n",
      "|    ep_rew_mean      | -30.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 185      |\n",
      "|    time_elapsed     | 1681     |\n",
      "|    total_timesteps  | 312228   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000495 |\n",
      "|    n_updates        | 178056   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.68e+03 |\n",
      "|    ep_rew_mean      | -30.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 185      |\n",
      "|    time_elapsed     | 1721     |\n",
      "|    total_timesteps  | 318849   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000221 |\n",
      "|    n_updates        | 179712   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.68e+03 |\n",
      "|    ep_rew_mean      | -30.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 184      |\n",
      "|    time_elapsed     | 1761     |\n",
      "|    total_timesteps  | 325461   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.001    |\n",
      "|    n_updates        | 181365   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.68e+03 |\n",
      "|    ep_rew_mean      | -30.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 184      |\n",
      "|    time_elapsed     | 1801     |\n",
      "|    total_timesteps  | 332130   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000931 |\n",
      "|    n_updates        | 183032   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.67e+03 |\n",
      "|    ep_rew_mean      | -30.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 183      |\n",
      "|    time_elapsed     | 1841     |\n",
      "|    total_timesteps  | 338685   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00242  |\n",
      "|    n_updates        | 184671   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.67e+03 |\n",
      "|    ep_rew_mean      | -30.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 183      |\n",
      "|    time_elapsed     | 1881     |\n",
      "|    total_timesteps  | 345340   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00175  |\n",
      "|    n_updates        | 186334   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.67e+03 |\n",
      "|    ep_rew_mean      | -31.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 183      |\n",
      "|    time_elapsed     | 1921     |\n",
      "|    total_timesteps  | 351960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000605 |\n",
      "|    n_updates        | 187989   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.67e+03 |\n",
      "|    ep_rew_mean      | -31.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 182      |\n",
      "|    time_elapsed     | 1961     |\n",
      "|    total_timesteps  | 358640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000751 |\n",
      "|    n_updates        | 189659   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.67e+03 |\n",
      "|    ep_rew_mean      | -31.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 182      |\n",
      "|    time_elapsed     | 2001     |\n",
      "|    total_timesteps  | 365367   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000428 |\n",
      "|    n_updates        | 191341   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -31.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 182      |\n",
      "|    time_elapsed     | 2041     |\n",
      "|    total_timesteps  | 372165   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 193041   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -31.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 182      |\n",
      "|    time_elapsed     | 2081     |\n",
      "|    total_timesteps  | 378889   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000315 |\n",
      "|    n_updates        | 194722   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -32.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 181      |\n",
      "|    time_elapsed     | 2121     |\n",
      "|    total_timesteps  | 385545   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000379 |\n",
      "|    n_updates        | 196386   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -31.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 181      |\n",
      "|    time_elapsed     | 2161     |\n",
      "|    total_timesteps  | 392256   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000401 |\n",
      "|    n_updates        | 198063   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -31.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 181      |\n",
      "|    time_elapsed     | 2201     |\n",
      "|    total_timesteps  | 398878   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000365 |\n",
      "|    n_updates        | 199719   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -31.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 180      |\n",
      "|    time_elapsed     | 2241     |\n",
      "|    total_timesteps  | 405594   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00489  |\n",
      "|    n_updates        | 201398   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -31.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 180      |\n",
      "|    time_elapsed     | 2281     |\n",
      "|    total_timesteps  | 412228   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000815 |\n",
      "|    n_updates        | 203056   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | -31.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 180      |\n",
      "|    time_elapsed     | 2321     |\n",
      "|    total_timesteps  | 418855   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 204713   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | -31.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 180      |\n",
      "|    time_elapsed     | 2361     |\n",
      "|    total_timesteps  | 425476   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 206368   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | -31.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 179      |\n",
      "|    time_elapsed     | 2401     |\n",
      "|    total_timesteps  | 432076   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000676 |\n",
      "|    n_updates        | 208018   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | -31.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 179      |\n",
      "|    time_elapsed     | 2441     |\n",
      "|    total_timesteps  | 438452   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000625 |\n",
      "|    n_updates        | 209612   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | -31.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 179      |\n",
      "|    time_elapsed     | 2481     |\n",
      "|    total_timesteps  | 444995   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000916 |\n",
      "|    n_updates        | 211248   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | -31.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 179      |\n",
      "|    time_elapsed     | 2521     |\n",
      "|    total_timesteps  | 451665   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000551 |\n",
      "|    n_updates        | 212916   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | -31.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 178      |\n",
      "|    time_elapsed     | 2561     |\n",
      "|    total_timesteps  | 458260   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000363 |\n",
      "|    n_updates        | 214564   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -31.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 178      |\n",
      "|    time_elapsed     | 2601     |\n",
      "|    total_timesteps  | 464909   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000246 |\n",
      "|    n_updates        | 216227   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -31.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 178      |\n",
      "|    time_elapsed     | 2641     |\n",
      "|    total_timesteps  | 471567   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 217891   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -31      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 178      |\n",
      "|    time_elapsed     | 2681     |\n",
      "|    total_timesteps  | 478120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000128 |\n",
      "|    n_updates        | 219529   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -30.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 178      |\n",
      "|    time_elapsed     | 2721     |\n",
      "|    total_timesteps  | 484808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00116  |\n",
      "|    n_updates        | 221201   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -30.7    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 2761     |\n",
      "|    total_timesteps  | 491307   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 222826   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | -30.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 2801     |\n",
      "|    total_timesteps  | 498503   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000266 |\n",
      "|    n_updates        | 224625   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.67e+03 |\n",
      "|    ep_rew_mean      | -30.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 2841     |\n",
      "|    total_timesteps  | 505548   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000708 |\n",
      "|    n_updates        | 226386   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.67e+03 |\n",
      "|    ep_rew_mean      | -30.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 2881     |\n",
      "|    total_timesteps  | 512573   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.95e-05 |\n",
      "|    n_updates        | 228143   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.68e+03 |\n",
      "|    ep_rew_mean      | -29.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 2921     |\n",
      "|    total_timesteps  | 519493   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000266 |\n",
      "|    n_updates        | 229873   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.68e+03 |\n",
      "|    ep_rew_mean      | -29.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 2961     |\n",
      "|    total_timesteps  | 526457   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000496 |\n",
      "|    n_updates        | 231614   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.68e+03 |\n",
      "|    ep_rew_mean      | -29.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3002     |\n",
      "|    total_timesteps  | 533446   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000836 |\n",
      "|    n_updates        | 233361   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.68e+03 |\n",
      "|    ep_rew_mean      | -29.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3042     |\n",
      "|    total_timesteps  | 540307   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00326  |\n",
      "|    n_updates        | 235076   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.68e+03 |\n",
      "|    ep_rew_mean      | -28.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3082     |\n",
      "|    total_timesteps  | 547185   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00178  |\n",
      "|    n_updates        | 236796   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.69e+03 |\n",
      "|    ep_rew_mean      | -28.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3122     |\n",
      "|    total_timesteps  | 554123   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 238530   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.69e+03 |\n",
      "|    ep_rew_mean      | -28.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3162     |\n",
      "|    total_timesteps  | 561017   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000521 |\n",
      "|    n_updates        | 240254   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.69e+03 |\n",
      "|    ep_rew_mean      | -28.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3202     |\n",
      "|    total_timesteps  | 567998   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00268  |\n",
      "|    n_updates        | 241999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.69e+03 |\n",
      "|    ep_rew_mean      | -29      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3242     |\n",
      "|    total_timesteps  | 574915   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 243728   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.7e+03  |\n",
      "|    ep_rew_mean      | -29.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3282     |\n",
      "|    total_timesteps  | 581849   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 245462   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.7e+03  |\n",
      "|    ep_rew_mean      | -28.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3322     |\n",
      "|    total_timesteps  | 588857   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 247214   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.7e+03  |\n",
      "|    ep_rew_mean      | -25      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3360     |\n",
      "|    total_timesteps  | 595251   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000117 |\n",
      "|    n_updates        | 248812   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.7e+03  |\n",
      "|    ep_rew_mean      | -24.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3400     |\n",
      "|    total_timesteps  | 602221   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000244 |\n",
      "|    n_updates        | 250555   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.71e+03 |\n",
      "|    ep_rew_mean      | -24.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3440     |\n",
      "|    total_timesteps  | 609193   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 252298   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.71e+03 |\n",
      "|    ep_rew_mean      | -24.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3480     |\n",
      "|    total_timesteps  | 616241   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00274  |\n",
      "|    n_updates        | 254060   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.72e+03 |\n",
      "|    ep_rew_mean      | -24.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3520     |\n",
      "|    total_timesteps  | 623296   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000198 |\n",
      "|    n_updates        | 255823   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.72e+03 |\n",
      "|    ep_rew_mean      | -24.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3560     |\n",
      "|    total_timesteps  | 630445   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000191 |\n",
      "|    n_updates        | 257611   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -24.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3600     |\n",
      "|    total_timesteps  | 637433   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000687 |\n",
      "|    n_updates        | 259358   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -24.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 3640     |\n",
      "|    total_timesteps  | 644393   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 261098   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -25      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 3680     |\n",
      "|    total_timesteps  | 651345   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00243  |\n",
      "|    n_updates        | 262836   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -25.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 3720     |\n",
      "|    total_timesteps  | 658334   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 264583   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -25.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 3760     |\n",
      "|    total_timesteps  | 665277   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000164 |\n",
      "|    n_updates        | 266319   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -25.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 3800     |\n",
      "|    total_timesteps  | 672276   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.73e-05 |\n",
      "|    n_updates        | 268068   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -25.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 3840     |\n",
      "|    total_timesteps  | 679272   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000276 |\n",
      "|    n_updates        | 269817   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -22.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 3878     |\n",
      "|    total_timesteps  | 685955   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00032  |\n",
      "|    n_updates        | 271488   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -22      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 3918     |\n",
      "|    total_timesteps  | 692869   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00159  |\n",
      "|    n_updates        | 273217   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -22.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 3958     |\n",
      "|    total_timesteps  | 699377   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000494 |\n",
      "|    n_updates        | 274844   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -22.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 3998     |\n",
      "|    total_timesteps  | 706402   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00281  |\n",
      "|    n_updates        | 276600   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -23      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4038     |\n",
      "|    total_timesteps  | 713325   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.42e-05 |\n",
      "|    n_updates        | 278331   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -23.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4078     |\n",
      "|    total_timesteps  | 720282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00208  |\n",
      "|    n_updates        | 280070   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -23      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4118     |\n",
      "|    total_timesteps  | 727332   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.11e-05 |\n",
      "|    n_updates        | 281832   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -23.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4159     |\n",
      "|    total_timesteps  | 734212   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00202  |\n",
      "|    n_updates        | 283552   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -23.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4199     |\n",
      "|    total_timesteps  | 741121   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000282 |\n",
      "|    n_updates        | 285280   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -23.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4239     |\n",
      "|    total_timesteps  | 748167   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000179 |\n",
      "|    n_updates        | 287041   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -23.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4279     |\n",
      "|    total_timesteps  | 755359   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000129 |\n",
      "|    n_updates        | 288839   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -24.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4319     |\n",
      "|    total_timesteps  | 762401   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.38e-05 |\n",
      "|    n_updates        | 290600   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -27.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4359     |\n",
      "|    total_timesteps  | 769366   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 292341   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -27.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4399     |\n",
      "|    total_timesteps  | 776311   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000885 |\n",
      "|    n_updates        | 294077   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -27.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4439     |\n",
      "|    total_timesteps  | 783086   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.8e-05  |\n",
      "|    n_updates        | 295771   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -27.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4479     |\n",
      "|    total_timesteps  | 790057   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000192 |\n",
      "|    n_updates        | 297514   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | -27.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4519     |\n",
      "|    total_timesteps  | 796797   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.11     |\n",
      "|    n_updates        | 299199   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -27.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4559     |\n",
      "|    total_timesteps  | 803781   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.11     |\n",
      "|    n_updates        | 300945   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -27.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4599     |\n",
      "|    total_timesteps  | 810779   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000412 |\n",
      "|    n_updates        | 302694   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -27.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4639     |\n",
      "|    total_timesteps  | 817706   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000161 |\n",
      "|    n_updates        | 304426   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -27.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4679     |\n",
      "|    total_timesteps  | 824639   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000409 |\n",
      "|    n_updates        | 306159   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | -27.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 4719     |\n",
      "|    total_timesteps  | 831560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.53e-05 |\n",
      "|    n_updates        | 307889   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\jupyter\\Reinforcement Learning\\CSE_465\\test.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/jupyter/Reinforcement%20Learning/CSE_465/test.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mlearn(total_timesteps\u001b[39m=\u001b[39m\u001b[39m1000000\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jahin\\anaconda3\\envs\\myenv\\Lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:267\u001b[0m, in \u001b[0;36mDQN.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    259\u001b[0m     \u001b[39mself\u001b[39m: SelfDQN,\n\u001b[0;32m    260\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    266\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfDQN:\n\u001b[1;32m--> 267\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mlearn(\n\u001b[0;32m    268\u001b[0m         total_timesteps\u001b[39m=\u001b[39mtotal_timesteps,\n\u001b[0;32m    269\u001b[0m         callback\u001b[39m=\u001b[39mcallback,\n\u001b[0;32m    270\u001b[0m         log_interval\u001b[39m=\u001b[39mlog_interval,\n\u001b[0;32m    271\u001b[0m         tb_log_name\u001b[39m=\u001b[39mtb_log_name,\n\u001b[0;32m    272\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39mreset_num_timesteps,\n\u001b[0;32m    273\u001b[0m         progress_bar\u001b[39m=\u001b[39mprogress_bar,\n\u001b[0;32m    274\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jahin\\anaconda3\\envs\\myenv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:312\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    309\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[0;32m    311\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 312\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollect_rollouts(\n\u001b[0;32m    313\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv,\n\u001b[0;32m    314\u001b[0m         train_freq\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_freq,\n\u001b[0;32m    315\u001b[0m         action_noise\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_noise,\n\u001b[0;32m    316\u001b[0m         callback\u001b[39m=\u001b[39mcallback,\n\u001b[0;32m    317\u001b[0m         learning_starts\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_starts,\n\u001b[0;32m    318\u001b[0m         replay_buffer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplay_buffer,\n\u001b[0;32m    319\u001b[0m         log_interval\u001b[39m=\u001b[39mlog_interval,\n\u001b[0;32m    320\u001b[0m     )\n\u001b[0;32m    322\u001b[0m     \u001b[39mif\u001b[39;00m rollout\u001b[39m.\u001b[39mcontinue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jahin\\anaconda3\\envs\\myenv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:559\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_info_buffer(infos, dones)\n\u001b[0;32m    558\u001b[0m \u001b[39m# Store data in replay buffer (normalized action and unnormalized observation)\u001b[39;00m\n\u001b[1;32m--> 559\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_transition(replay_buffer, buffer_actions, new_obs, rewards, dones, infos)\n\u001b[0;32m    561\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_current_progress_remaining(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_total_timesteps)\n\u001b[0;32m    563\u001b[0m \u001b[39m# For DQN, check if the target network should be updated\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# and update the exploration schedule\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39m# For SAC/TD3, the update is dones as the same time as the gradient update\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39m# see https://github.com/hill-a/stable-baselines/issues/900\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jahin\\anaconda3\\envs\\myenv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:472\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._store_transition\u001b[1;34m(self, replay_buffer, buffer_action, new_obs, reward, dones, infos)\u001b[0m\n\u001b[0;32m    469\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vec_normalize_env \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m                 next_obs[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vec_normalize_env\u001b[39m.\u001b[39munnormalize_obs(next_obs[i, :])\n\u001b[1;32m--> 472\u001b[0m replay_buffer\u001b[39m.\u001b[39madd(\n\u001b[0;32m    473\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_original_obs,\n\u001b[0;32m    474\u001b[0m     next_obs,\n\u001b[0;32m    475\u001b[0m     buffer_action,\n\u001b[0;32m    476\u001b[0m     reward_,\n\u001b[0;32m    477\u001b[0m     dones,\n\u001b[0;32m    478\u001b[0m     infos,\n\u001b[0;32m    479\u001b[0m )\n\u001b[0;32m    481\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_obs \u001b[39m=\u001b[39m new_obs\n\u001b[0;32m    482\u001b[0m \u001b[39m# Save the unnormalized observation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jahin\\anaconda3\\envs\\myenv\\Lib\\site-packages\\stable_baselines3\\common\\buffers.py:610\u001b[0m, in \u001b[0;36mDictReplayBuffer.add\u001b[1;34m(self, obs, next_obs, action, reward, done, infos)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space\u001b[39m.\u001b[39mspaces[key], spaces\u001b[39m.\u001b[39mDiscrete):\n\u001b[0;32m    609\u001b[0m         obs[key] \u001b[39m=\u001b[39m obs[key]\u001b[39m.\u001b[39mreshape((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_envs,) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_shape[key])\n\u001b[1;32m--> 610\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservations[key][\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(obs[key])\n\u001b[0;32m    612\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_observations\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    613\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space\u001b[39m.\u001b[39mspaces[key], spaces\u001b[39m.\u001b[39mDiscrete):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(baseline_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load(baseline_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GameEnv(render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jahin\\anaconda3\\envs\\myenv\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-85.51028055180795, 0.3385999429223491)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
